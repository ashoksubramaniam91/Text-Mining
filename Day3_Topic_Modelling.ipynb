{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon=pd.read_csv('C:\\\\Users\\\\Ashok\\\\Desktop\\\\Text_Mining\\\\Topic modelling\\\\amazon_reviews_big.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000HDJXNA</td>\n",
       "      <td>1</td>\n",
       "      <td>What I recieved is not what is pictured here O...</td>\n",
       "      <td>12 26, 2012</td>\n",
       "      <td>A29YXBFTD7QUP3</td>\n",
       "      <td>HHA</td>\n",
       "      <td>Buyer be ware</td>\n",
       "      <td>1.356480e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B006KKS7XQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent unit and a pretty simple install usi...</td>\n",
       "      <td>09 20, 2013</td>\n",
       "      <td>A3IMTXFYD7CGDN</td>\n",
       "      <td>Peter W. George \"soyflakeman\"</td>\n",
       "      <td>high quality without high price</td>\n",
       "      <td>1.379635e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002NP8XJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm enjoying this keyboard, I'm getting anothe...</td>\n",
       "      <td>08 31, 2010</td>\n",
       "      <td>AXNOW20FQKHVW</td>\n",
       "      <td>B. Hayashi</td>\n",
       "      <td>Superb keyboard + solution for slow wake up an...</td>\n",
       "      <td>1.283213e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000EITTLE</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall, this is a fantastic camera that I'm e...</td>\n",
       "      <td>02 3, 2008</td>\n",
       "      <td>A10KCAK279LO0W</td>\n",
       "      <td>mmcwatters \"macdadi80\"</td>\n",
       "      <td>One qualm: not great in low light</td>\n",
       "      <td>1.201997e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006CRXK4S</td>\n",
       "      <td>5</td>\n",
       "      <td>These work very well with mySamsung PN64D7000 ...</td>\n",
       "      <td>01 28, 2012</td>\n",
       "      <td>A19XXLMZXR764J</td>\n",
       "      <td>S. Garfinkle</td>\n",
       "      <td>Work great, fit well</td>\n",
       "      <td>1.327709e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  B000HDJXNA        1  What I recieved is not what is pictured here O...   \n",
       "1  B006KKS7XQ        5  Excellent unit and a pretty simple install usi...   \n",
       "2  B002NP8XJ0        5  I'm enjoying this keyboard, I'm getting anothe...   \n",
       "3  B000EITTLE        4  Overall, this is a fantastic camera that I'm e...   \n",
       "4  B006CRXK4S        5  These work very well with mySamsung PN64D7000 ...   \n",
       "\n",
       "    reviewTime      reviewerID                   reviewerName  \\\n",
       "0  12 26, 2012  A29YXBFTD7QUP3                            HHA   \n",
       "1  09 20, 2013  A3IMTXFYD7CGDN  Peter W. George \"soyflakeman\"   \n",
       "2  08 31, 2010   AXNOW20FQKHVW                     B. Hayashi   \n",
       "3   02 3, 2008  A10KCAK279LO0W         mmcwatters \"macdadi80\"   \n",
       "4  01 28, 2012  A19XXLMZXR764J                   S. Garfinkle   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0                                      Buyer be ware    1.356480e+09  \n",
       "1                    high quality without high price    1.379635e+09  \n",
       "2  Superb keyboard + solution for slow wake up an...    1.283213e+09  \n",
       "3                  One qualm: not great in low light    1.201997e+09  \n",
       "4                               Work great, fit well    1.327709e+09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon.shape   #Amazon review data\n",
    "               #jmcauley.ucsd.edu/data/amazon/\n",
    "    #reviews for ach category large file\n",
    "    #it will be in json format convert it to csv(every file is of 2gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # we will be using only review text as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=Amazon['reviewText'].fillna('NA').str.lower().str.replace('[^a-z ]','')\n",
    "docs_clean=[]\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['na',\"\",'use','get'])\n",
    "stemmer=nltk.stem.PorterStemmer()\n",
    "for doc in docs:\n",
    "    words=doc.split(' ')\n",
    "    words_clean=[stemmer.stem(word) for word in words if word not in stopwords]\n",
    "    docs_clean.append(words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim needs data in list format, every doc will be a list, so it is list of list                    #page-001\n",
    "#scikit learn will compress the dtm matrix\n",
    "#gensim also excepts a compressed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: to create id for every unique words\n",
    "dictionary=gensim.corpora.Dictionary(docs_clean) \n",
    "docs_bow=[]\n",
    "for doc in docs_clean:\n",
    "    bow=dictionary.doc2bow(doc)   #looping through each docunemt and creates bag of words structure....refer notes\n",
    "    docs_bow.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 2),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 5),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 3),\n",
       " (11, 2),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 2),\n",
       " (19, 1),\n",
       " (20, 2),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 2),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 2),\n",
       " (36, 2),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (48, 1),\n",
       " (49, 1),\n",
       " (50, 1),\n",
       " (51, 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_bow[0] #bow for first document\n",
    "#ca get for every word what is the id, using key of the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now diving the atrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x36a80f60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=gensim.models.LdaModel(docs_bow,id2word=dictionary,num_topics=8)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"one\" + 0.017*\"work\" + 0.011*\"time\" + 0.009*\"would\" + 0.008*\"mous\" + 0.008*\"product\" + 0.007*\"use\" + 0.007*\"unit\" + 0.007*\"year\" + 0.007*\"batteri\"'),\n",
       " (1,\n",
       "  '0.040*\"drive\" + 0.037*\"cabl\" + 0.030*\"usb\" + 0.027*\"work\" + 0.018*\"power\" + 0.016*\"plug\" + 0.014*\"port\" + 0.012*\"need\" + 0.012*\"adapt\" + 0.011*\"connect\"'),\n",
       " (2,\n",
       "  '0.041*\"camera\" + 0.018*\"len\" + 0.017*\"batteri\" + 0.009*\"pictur\" + 0.009*\"take\" + 0.009*\"use\" + 0.009*\"great\" + 0.008*\"canon\" + 0.008*\"good\" + 0.007*\"qualiti\"'),\n",
       " (3,\n",
       "  '0.036*\"case\" + 0.015*\"fit\" + 0.013*\"ipad\" + 0.012*\"like\" + 0.011*\"cover\" + 0.011*\"protect\" + 0.011*\"well\" + 0.010*\"great\" + 0.010*\"one\" + 0.009*\"look\"'),\n",
       " (4,\n",
       "  '0.017*\"card\" + 0.014*\"devic\" + 0.013*\"work\" + 0.011*\"router\" + 0.011*\"connect\" + 0.009*\"wireless\" + 0.008*\"use\" + 0.008*\"gb\" + 0.007*\"comput\" + 0.007*\"window\"'),\n",
       " (5,\n",
       "  '0.031*\"tv\" + 0.017*\"video\" + 0.012*\"remot\" + 0.011*\"set\" + 0.010*\"pictur\" + 0.010*\"player\" + 0.010*\"monitor\" + 0.009*\"dvd\" + 0.009*\"watch\" + 0.009*\"play\"'),\n",
       " (6,\n",
       "  '0.014*\"keyboard\" + 0.010*\"like\" + 0.010*\"mount\" + 0.008*\"use\" + 0.008*\"screen\" + 0.008*\"one\" + 0.007*\"key\" + 0.007*\"light\" + 0.006*\"make\" + 0.006*\"littl\"'),\n",
       " (7,\n",
       "  '0.029*\"sound\" + 0.016*\"speaker\" + 0.012*\"good\" + 0.011*\"qualiti\" + 0.011*\"headphon\" + 0.010*\"great\" + 0.009*\"music\" + 0.008*\"like\" + 0.007*\"ear\" + 0.007*\"price\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topics() #this is the second matrix\n",
    "#topic to term relation , for every topic we will pic top 10 words...divide every row/rowsum...\n",
    "#for every top pick 10 which are high probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is a empty string at the staring of every topic...add all these to stopwords and rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.18458976),\n",
       " (1, 0.030860767),\n",
       " (3, 0.28052247),\n",
       " (6, 0.16442959),\n",
       " (7, 0.33311653)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_document_topics(docs_bow[1])  #1st matric after\n",
    "\n",
    "# for document 1 #35% of worda are related to topic 1, 22% of words are related to topic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.38268495),\n",
       " (3, 0.20073348),\n",
       " (4, 0.18438724),\n",
       " (6, 0.20035563),\n",
       " (7, 0.029203072)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_document_topics(docs_bow[2])\n",
    "#topic 2 has highest prob so ill assign it as topic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=[]\n",
    "for bow in docs_bow:\n",
    "    temp=pd.DataFrame(model.get_document_topics(bow),\n",
    "                     columns=['topic','probability'])\n",
    "    topic=temp.sort_values(by='probability',ascending=False).iloc[0]['topic']\n",
    "    topics.append(topic)\n",
    "Amazon['topic']=topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    18854\n",
       "3.0    15910\n",
       "7.0    14770\n",
       "1.0    11865\n",
       "2.0    11728\n",
       "6.0     9919\n",
       "4.0     9647\n",
       "5.0     7307\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon['topic'].value_counts()\n",
    "#model.get_document_topics(docs_bow[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000HDJXNA</td>\n",
       "      <td>1</td>\n",
       "      <td>What I recieved is not what is pictured here O...</td>\n",
       "      <td>12 26, 2012</td>\n",
       "      <td>A29YXBFTD7QUP3</td>\n",
       "      <td>HHA</td>\n",
       "      <td>Buyer be ware</td>\n",
       "      <td>1.356480e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B006KKS7XQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent unit and a pretty simple install usi...</td>\n",
       "      <td>09 20, 2013</td>\n",
       "      <td>A3IMTXFYD7CGDN</td>\n",
       "      <td>Peter W. George \"soyflakeman\"</td>\n",
       "      <td>high quality without high price</td>\n",
       "      <td>1.379635e+09</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002NP8XJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm enjoying this keyboard, I'm getting anothe...</td>\n",
       "      <td>08 31, 2010</td>\n",
       "      <td>AXNOW20FQKHVW</td>\n",
       "      <td>B. Hayashi</td>\n",
       "      <td>Superb keyboard + solution for slow wake up an...</td>\n",
       "      <td>1.283213e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000EITTLE</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall, this is a fantastic camera that I'm e...</td>\n",
       "      <td>02 3, 2008</td>\n",
       "      <td>A10KCAK279LO0W</td>\n",
       "      <td>mmcwatters \"macdadi80\"</td>\n",
       "      <td>One qualm: not great in low light</td>\n",
       "      <td>1.201997e+09</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006CRXK4S</td>\n",
       "      <td>5</td>\n",
       "      <td>These work very well with mySamsung PN64D7000 ...</td>\n",
       "      <td>01 28, 2012</td>\n",
       "      <td>A19XXLMZXR764J</td>\n",
       "      <td>S. Garfinkle</td>\n",
       "      <td>Work great, fit well</td>\n",
       "      <td>1.327709e+09</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  B000HDJXNA        1  What I recieved is not what is pictured here O...   \n",
       "1  B006KKS7XQ        5  Excellent unit and a pretty simple install usi...   \n",
       "2  B002NP8XJ0        5  I'm enjoying this keyboard, I'm getting anothe...   \n",
       "3  B000EITTLE        4  Overall, this is a fantastic camera that I'm e...   \n",
       "4  B006CRXK4S        5  These work very well with mySamsung PN64D7000 ...   \n",
       "\n",
       "    reviewTime      reviewerID                   reviewerName  \\\n",
       "0  12 26, 2012  A29YXBFTD7QUP3                            HHA   \n",
       "1  09 20, 2013  A3IMTXFYD7CGDN  Peter W. George \"soyflakeman\"   \n",
       "2  08 31, 2010   AXNOW20FQKHVW                     B. Hayashi   \n",
       "3   02 3, 2008  A10KCAK279LO0W         mmcwatters \"macdadi80\"   \n",
       "4  01 28, 2012  A19XXLMZXR764J                   S. Garfinkle   \n",
       "\n",
       "                                             summary  unixReviewTime  topic  \n",
       "0                                      Buyer be ware    1.356480e+09    0.0  \n",
       "1                    high quality without high price    1.379635e+09    7.0  \n",
       "2  Superb keyboard + solution for slow wake up an...    1.283213e+09    0.0  \n",
       "3                  One qualm: not great in low light    1.201997e+09    2.0  \n",
       "4                               Work great, fit well    1.327709e+09    3.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
